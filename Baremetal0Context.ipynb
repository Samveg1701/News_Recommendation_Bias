{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYH4c3SQxl3S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the Hugging Face token\n",
        "os.environ[\"HF_HOME\"] = \"/content/huggingface/cache\"\n",
        "os.environ[\"HF_TOKEN\"] = \"HF_TOKEN\"\n",
        "!pip install transformers torch accelerate\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\" # meta-llama/Llama-2-7b-hf\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, use_auth_token=True)\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",  # LLM task\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "def get_llama_response(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response from the Llama model.\n",
        "\n",
        "    Parameters:\n",
        "        prompt (str): The user's input/question for the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response (expected to be 'positive', 'negative', or 'neutral').\n",
        "    \"\"\"\n",
        "    sequences = llama_pipeline(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_length=512,\n",
        "    )\n",
        "    # Assuming the response is the sentiment we need, extract and clean it\n",
        "    response_text = sequences[0]['generated_text']\n",
        "    print(response_text)\n",
        "    # Process the response text to find the sentiment word\n",
        "    sentiment = response_text.split()[-1]  # Assuming the last word is the sentiment\n",
        "    print(\"Predicted Sentiment:\", sentiment)\n",
        "    return sentiment\n",
        "\n",
        "def sentiment_analysis(article: str) -> None:\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of a given article using the Llama model.\n",
        "\n",
        "    Parameters:\n",
        "        article (str): The article text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints the predicted sentiment of the article.\n",
        "    \"\"\"\n",
        "    positive_example = 'Great Lakes leaders pledge peace. Presidents of the Great Lakes region in Africa have signed a declaration designed to bring peace to the region.'\n",
        "    negative_example = \"\"\"'Ballesteros Under Tour Probe for Alleged Assault. SOTOGRANDE, Spain (Reuters) - Severiano Ballesteros is to be investigated by the European Tour following an alleged assault on one of the tour's tournament directors at his home course Pedrena.\"\"\"\n",
        "    prompt = f\"This is an example of an article with a positive sentiment: {positive_example} This is an example of an article with negative sentiment: {negative_example} Given this, predict the sentiment of the following article as positive, negative, or neutral in only one word: {article}\\n\"\n",
        "    get_llama_response(prompt)\n",
        "\n",
        "    # article_2= \"\"\"Great Lakes leaders pledge peace Presidents of the Great Lakes region in Africa have signed a declaration designed bring peace to the region. \"\"\"\n",
        "    # prompt_2 = f\"\"\"\n",
        "    # Act as a sentiment analyzer for a media outlet. This is an example of {positive_example} article with a positive sentiment. This is an example of {negative_example} of article with negative sentiment. Classify <example> as positive, negative or neutral.\n",
        "    # {article_2}\n",
        "    # \"\"\"\n",
        "    # get_llama_response(prompt_2)\n",
        "\n",
        "# Example usage\n",
        "template = \"\"\"\n",
        "Please generate an answer to the following question using any relevant information from the provided context:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "custom_rag_prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n",
        "\n",
        "\n",
        "article = \"Inflation fears, oil swings to keep sentiment low MUMBAI: The market is expected to remain volatile ahead of the expiry of futures contract on Thursday. The mood will remain subdued amid worries over a fresh rise in global crude oil prices and inflation in the country, say brokers.\"\n",
        "sentiment_analysis(article)\n",
        "\n",
        "\n",
        "prompt = \"\"\"\n",
        "Give 50 article headlines about the Israel-Palestine war along with their source\n",
        "\"\"\"\n",
        "response = get_llama_response(prompt)\n",
        "print(response)\n",
        "\n",
        "\n",
        "def sentiment_analysis(article):\n",
        "  positive_article = 'Great Lakes leaders pledge peace Presidents of the Great Lakes region in Africa have signed a declaration designed bring peace to the region'\n",
        "  negative_article = \"\"\"'Ballesteros Under Tour Probe for Alleged Assault SOTOGRANDE, Spain (Reuters) - Severiano Ballesteros is to be investigated by the European Tour following an alleged assault on one of the tour's tournament directors at his home course Pedrena\"\"\"\n",
        "  # article = ''\n",
        "  # prompt = f\"\"\"What is the sentiment of  {article} article. Respond with either positive, negative, or neutral.\"\"\"\n",
        "  # get_llama_response(prompt)\n",
        "  # article = ''\n",
        "  prompt = f\"\"\"This is an example of {positive_article} article with a positive sentiment. This is a example of {negative_article} of article\n",
        "  with negative sentiment Given this, predict the sentiment of the following article as positive, negative, or neutral.\n",
        "  {article}\n",
        "  \"\"\"\n",
        "  get_llama_response(prompt)\n",
        "  # prompt = f\"\"\"\n",
        "  # Act as a sentiment analyzer for a media outlet. This is an example of {positive_article} article with a positive sentiment. This is an example of {negative_article} of article with negative sentiment. Classify <example> as positive, negative or neutral.\n",
        "  # {article}\n",
        "  # \"\"\"\n",
        "  # get_llama_response(prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
